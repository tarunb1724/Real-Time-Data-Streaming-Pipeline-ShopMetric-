# Real-Time-Data-Streaming-Pipeline-ShopMetric-
ShopMetric is a scalable, real-time ETL pipeline that ingests simulated high-volume e-commerce orders via Kafka, processes them with Spark Structured Streaming, and archives raw data to AWS S3 while serving analytics through Snowflake.

# ğŸ›’ ShopMetric â€” Real-Time E-Commerce Data Pipeline

**ShopMetric** is an end-to-end **real-time data engineering project** that simulates, processes, stores, and visualizes e-commerce transactions at scale.

It demonstrates how modern streaming systems work together using **Apache Kafka**, **Apache Spark Structured Streaming**, **AWS S3**, and **Snowflake**, following real-world data architecture best practices.

---

## ğŸ“Œ Project Highlights

- Real-time event streaming with **Kafka**
- Distributed stream processing with **Spark**
- Hybrid storage architecture:
  - **AWS S3** â†’ Data Lake (raw & historical data)
  - **Snowflake** â†’ Data Warehouse (analytics-ready data)
- Fully containerized with **Docker & Docker Compose**
- Designed for **scalability, fault tolerance, and analytics**

---

## ğŸ— Architecture â€” *The Pizza Shop Model ğŸ•*

| Layer | Component | Description |
|-----|----------|-------------|
| ğŸ§‘â€ğŸ¤â€ğŸ§‘ Source | Customers | Python script generates fake orders |
| ğŸ§¾ Ingestion | Kafka (Waiter) | Buffers high-throughput events |
| ğŸ‘¨â€ğŸ³ Processing | Spark (Chef) | Cleans & filters streaming data |
| ğŸ—„ Storage | AWS S3 (Basement) | Stores raw historical data |
| ğŸ“Š Analytics | Snowflake (Display) | Stores curated analytics data |
| ğŸ“ˆ Visualization | Streamlit (Scoreboard) | Live dashboards *(in progress)* |

---

## ğŸ›  Tech Stack

- **Language:** Python 3.9+
- **Containerization:** Docker, Docker Compose
- **Message Broker:** Apache Kafka, Zookeeper
- **Stream Processing:** Apache Spark (PySpark)
- **Data Lake:** AWS S3
- **Data Warehouse:** Snowflake *(In Progress)*
- **Visualization:** Streamlit *(In Progress)*

---

## ğŸ“‚ Project Structure

```text
ShopMetric/
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ generator.py           # Kafka data generator
â”‚
â”œâ”€â”€ spark_processor.py         # Spark streaming job
â”‚
â”œâ”€â”€ user-jars/                 # Spark external JARs
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

### 2. Clone the Repository
```bash
git clone [https://github.com/yourusername/ShopMetric.git](https://github.com/yourusername/ShopMetric.git)
cd ShopMetric
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install kafka-python faker pyspark
docker-compose up -d
python scripts/generator.py
